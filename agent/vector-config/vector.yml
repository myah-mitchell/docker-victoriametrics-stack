data_dir: "/var/lib/vector"

api:
  enabled: true
  address: 0.0.0.0:8686

sources:
  docker_socket:
    type: docker_logs
    include_containers: # Optional: Include all by default, or specific lists
      - "*" 
    # auto_partial_merge: true helps reconstruct split long log lines
  vector_metrics:
    type: internal_metrics

transforms:
  # Process and structure the logs
  process_logs:
    type: "remap"
    inputs: ["docker_socket"]
    source: |
      # 1. Clean up Metadata
      # Docker container names often come with a leading slash (e.g., "/traefik").
      # We strip it for cleaner querying in VictoriaLogs.
      .container_name = replace(.container_name, "/", "") ?? .container_name

      # 2. Structured Log Parsing
      # Many modern apps (Traefik, Caddy, Go apps) log in JSON.
      # We attempt to parse the 'message' field as JSON.
      structured, err = parse_json(.message)

      if err == null {
        # If successful, merge the JSON keys to the root of the event.
        # This makes fields like "level", "status_code", "duration" top-level fields in VictoriaLogs.
        . = merge(., structured)
        
        # 3. Message Normalization
        # VictoriaLogs looks for a message content. If the JSON had a 'msg' or 'message' field,
        # we ensure it stays as the main payload.
        if exists(.msg) {
          .message = .msg
          del(.msg)
        }
      } 
      # If parsing fails (e.g., standard plain text log), .message remains as is.

sinks:
  # Send to VictoriaLogs (via VLAgent) using the native JSON Line format
  # This is more efficient than the Elasticsearch sink as it avoids the bulk API overhead.
  victorialogs:
    type: "http"
    inputs: ["parse_docker"]
    uri: "http://vlagent:9429/insert/jsonline/"
    method: "post"
    compression: "gzip"
    encoding:
      codec: "ndjson" # Newline Delimited JSON - the native format for VL
      timestamp_format: "rfc3339"

    # Best Practice Headers for VictoriaLogs Native Ingestion
    request:
      headers:
        # Tells VL to look inside the JSON for a field named "container_name" to group logs
        VL-Stream-Fields: "container_name"
        # Tells VL which field contains the actual timestamp (Vector uses 'timestamp' by default)
        VL-Time-Field: "timestamp"
        # Tells VL which field contains the log message
        VL-Msg-Field: "message"
        # Optional: Helps debug if you have multiple Vector instances
        User-Agent: "vector-sink"

    # Batching settings to optimize network throughput
    batch:
      max_bytes: 1048576 # 1MB batches
      timeout_secs: 1    # Or send whatever we have every 1 second
      
    healthcheck:
      enabled: true

  victoriametrics:
    type: prometheus_remote_write
    endpoint: http://vmagent:8429/api/v1/write
    inputs: [vector_metrics]
    healthcheck:
      enabled: false